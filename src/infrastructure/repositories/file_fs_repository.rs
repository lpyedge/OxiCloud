use std::path::PathBuf;
use std::sync::Arc;
use std::time::Duration;
use async_trait::async_trait;
use tokio::{fs, io::AsyncWriteExt, time};
use tokio::fs::File as TokioFile;
use tokio_util::codec::{BytesCodec, FramedRead};
use mime_guess::from_path;
use futures::{Stream, StreamExt};
use bytes::Bytes;
use tokio::task;

use crate::domain::entities::file::File;
use crate::domain::repositories::file_repository::{
    FileRepository, FileRepositoryError, FileRepositoryResult
};
use crate::application::services::storage_mediator::StorageMediator;
use crate::application::ports::outbound::IdMappingPort;
use crate::infrastructure::services::id_mapping_service::IdMappingError;
use crate::infrastructure::services::file_metadata_cache::{FileMetadataCache, CacheEntryType};
use crate::domain::services::path_service::{StoragePath, PathService};
use crate::common::errors::{DomainError, ErrorContext};
use crate::common::config::AppConfig;
use crate::application::ports::outbound::FileStoragePort;
use crate::infrastructure::repositories::parallel_file_processor::ParallelFileProcessor;

// Usar constantes de la configuración centralizada en lugar de valores fijos
// Esto se reemplaza con self.config.concurrency.max_concurrent_files más adelante

/// Filesystem implementation of the FileRepository interface
pub struct FileFsRepository {
    root_path: PathBuf,
    storage_mediator: Arc<dyn StorageMediator>,
    id_mapping_service: Arc<dyn crate::application::ports::outbound::IdMappingPort>,
    path_service: Arc<PathService>,
    metadata_cache: Arc<FileMetadataCache>,
    config: AppConfig,
    parallel_processor: Option<Arc<ParallelFileProcessor>>,
}

impl FileFsRepository {
    /// Creates a new filesystem-based file repository
    #[allow(dead_code)]
    pub fn new(
        root_path: PathBuf, 
        storage_mediator: Arc<dyn StorageMediator>,
        id_mapping_service: Arc<dyn crate::application::ports::outbound::IdMappingPort>,
        path_service: Arc<PathService>,
        metadata_cache: Arc<FileMetadataCache>,
    ) -> Self {
        Self { 
            root_path, 
            storage_mediator, 
            id_mapping_service,
            path_service,
            metadata_cache,
            config: AppConfig::default(),
            parallel_processor: None,
        }
    }
    
    /// Creates a new repository with a pre-configured parallel file processor
    pub fn new_with_processor(
        root_path: PathBuf, 
        storage_mediator: Arc<dyn StorageMediator>,
        id_mapping_service: Arc<dyn crate::application::ports::outbound::IdMappingPort>,
        path_service: Arc<PathService>,
        metadata_cache: Arc<FileMetadataCache>,
        parallel_processor: Arc<ParallelFileProcessor>,
    ) -> Self {
        Self { 
            root_path, 
            storage_mediator, 
            id_mapping_service,
            path_service,
            metadata_cache,
            config: AppConfig::default(),
            parallel_processor: Some(parallel_processor),
        }
    }
    
    /// Resolves a domain storage path to an absolute filesystem path
    fn resolve_storage_path(&self, storage_path: &StoragePath) -> PathBuf {
        self.path_service.resolve_path(storage_path)
    }
    
    /// Resolves a legacy PathBuf to an absolute filesystem path
    #[allow(dead_code)]
    fn resolve_legacy_path(&self, relative_path: &std::path::Path) -> PathBuf {
        self.storage_mediator.resolve_path(relative_path)
    }
    
    /// Checks if a file exists at a given storage path
    async fn file_exists_at_storage_path(&self, storage_path: &StoragePath) -> FileRepositoryResult<bool> {
        let abs_path = self.resolve_storage_path(storage_path);
        
        // Intentar obtener del caché avanzado primero
        if let Some(is_file) = self.metadata_cache.is_file(&abs_path).await {
            tracing::debug!("Metadata cache hit for existence check: {} - path: {}", is_file, abs_path.display());
            return Ok(is_file);
        }
        
        // Si no está en caché, verificar directamente y actualizar caché
        tracing::debug!("Metadata cache miss for existence check: {}", abs_path.display());
        
        // Utilizar timeout para evitar bloqueo
        match time::timeout(
            self.config.timeouts.file_timeout(),
            fs::metadata(&abs_path)
        ).await {
            Ok(Ok(metadata)) => {
                let is_file = metadata.is_file();
                
                // Actualizar la caché con información fresca
                if let Err(e) = self.metadata_cache.refresh_metadata(&abs_path).await {
                    tracing::warn!("Failed to update cache for {}: {}", abs_path.display(), e);
                }
                
                if is_file {
                    tracing::debug!("File exists and is accessible: {}", abs_path.display());
                    Ok(true)
                } else {
                    tracing::warn!("Path exists but is not a file: {}", abs_path.display());
                    Ok(false)
                }
            },
            Ok(Err(e)) => {
                tracing::warn!("File check failed: {} - {}", abs_path.display(), e);
                
                // Añadir a caché como no existente
                let entry_type = CacheEntryType::Unknown;
                let file_metadata = crate::infrastructure::services::file_metadata_cache::FileMetadata::new(
                    abs_path.clone(),
                    false,
                    entry_type,
                    None,
                    None,
                    None,
                    None,
                    Duration::from_millis(self.config.timeouts.file_operation_ms),
                );
                self.metadata_cache.update_cache(file_metadata).await;
                
                Ok(false)
            },
            Err(_) => {
                tracing::warn!("Timeout checking file metadata: {}", abs_path.display());
                return Err(FileRepositoryError::Timeout(format!("Timeout checking file: {}", abs_path.display())));
            }
        }
    }
    
    /// Legacy method for checking file existence with PathBuf
    #[allow(dead_code)]
    async fn file_exists(&self, path: &std::path::Path) -> FileRepositoryResult<bool> {
        let abs_path = self.resolve_legacy_path(path);
        
        // Intentar obtener del caché avanzado primero
        if let Some(is_file) = self.metadata_cache.is_file(&abs_path).await {
            tracing::debug!("Metadata cache hit for legacy existence check: {} - path: {}", is_file, abs_path.display());
            return Ok(is_file);
        }
        
        // Si no está en caché, verificar directamente
        tracing::info!("Checking if file exists: {} - path: {}", abs_path.exists(), abs_path.display());
        
        match time::timeout(
            self.config.timeouts.file_timeout(),
            fs::metadata(&abs_path)
        ).await {
            Ok(Ok(metadata)) => {
                let is_file = metadata.is_file();
                
                // Actualizar la caché con información fresca
                if let Err(e) = self.metadata_cache.refresh_metadata(&abs_path).await {
                    tracing::warn!("Failed to update cache for {}: {}", abs_path.display(), e);
                }
                
                if is_file {
                    tracing::info!("File exists and is accessible: {}", abs_path.display());
                    return Ok(true);
                } else {
                    tracing::warn!("Path exists but is not a file: {}", abs_path.display());
                    return Ok(false);
                }
            },
            Ok(Err(e)) => {
                tracing::warn!("File exists but metadata check failed: {} - {}", abs_path.display(), e);
                return Ok(false);
            },
            Err(_) => {
                tracing::warn!("Timeout checking file metadata: {}", abs_path.display());
                return Err(FileRepositoryError::Timeout(format!("Timeout checking file: {}", abs_path.display())));
            }
        }
    }
    
    /// Helper method to create a File entity from a storage path and metadata
    async fn create_file_entity(
        &self,
        id: String,
        name: String,
        storage_path: StoragePath,
        size: u64,
        mime_type: String,
        folder_id: Option<String>,
        created_at: Option<u64>,
        modified_at: Option<u64>,
    ) -> FileRepositoryResult<File> {
        // If timestamps are provided, use them; otherwise, let File::new create default timestamps
        if let (Some(created), Some(modified)) = (created_at, modified_at) {
            File::with_timestamps(
                id, 
                name, 
                storage_path, 
                size, 
                mime_type, 
                folder_id,
                created,
                modified,
            )
            .map_err(|e| FileRepositoryError::Other(e.to_string()))
        } else {
            File::new(
                id, 
                name, 
                storage_path, 
                size, 
                mime_type, 
                folder_id,
            )
            .map_err(|e| FileRepositoryError::Other(e.to_string()))
        }
    }
    
    /// Extracts file metadata from a physical path with timeout and cache
    async fn get_file_metadata(&self, abs_path: &PathBuf) -> FileRepositoryResult<(u64, u64, u64)> {
        // Intentar obtener de caché primero
        if let Some(cached_metadata) = self.metadata_cache.get_metadata(abs_path).await {
            if let (Some(size), Some(created_at), Some(modified_at)) = 
                (cached_metadata.size, cached_metadata.created_at, cached_metadata.modified_at) {
                tracing::debug!("Using cached metadata for: {}", abs_path.display());
                return Ok((size, created_at, modified_at));
            }
        }
        
        // Si no está en caché o metadatos incompletos, cargar desde sistema de archivos
        let metadata = match time::timeout(
            self.config.timeouts.file_timeout(),
            fs::metadata(&abs_path)
        ).await {
            Ok(Ok(metadata)) => metadata,
            Ok(Err(e)) => return Err(FileRepositoryError::IoError(e)),
            Err(_) => return Err(FileRepositoryError::Timeout(
                format!("Timeout getting metadata for: {}", abs_path.display())
            )),
        };
        
        let size = metadata.len();
        
        // Get creation timestamp
        let created_at = metadata.created()
            .map(|time| time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs())
            .unwrap_or_else(|_| 0);
            
        // Get modification timestamp
        let modified_at = metadata.modified()
            .map(|time| time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs())
            .unwrap_or_else(|_| 0);
        
        // Actualizar caché si es posible
        if let Err(e) = self.metadata_cache.refresh_metadata(abs_path).await {
            tracing::warn!("Failed to update metadata cache for {}: {}", abs_path.display(), e);
        }
            
        Ok((size, created_at, modified_at))
    }
    
    /// Creates parent directories if needed with timeout
    async fn ensure_parent_directory(&self, abs_path: &PathBuf) -> FileRepositoryResult<()> {
        if let Some(parent) = abs_path.parent() {
            time::timeout(
                self.config.timeouts.dir_timeout(),
                fs::create_dir_all(parent)
            ).await
            .map_err(|_| FileRepositoryError::Timeout(
                format!("Timeout creating parent directory: {}", parent.display())
            ))?
            .map_err(FileRepositoryError::IoError)?;
        }
        Ok(())
    }
    
    /// Check if a file is large based on size threshold from config
    async fn is_large_file(&self, abs_path: &PathBuf) -> FileRepositoryResult<bool> {
        if !abs_path.exists() {
            return Ok(false);
        }
        
        let metadata = time::timeout(
            self.config.timeouts.file_timeout(),
            fs::metadata(&abs_path)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout checking file size: {}", abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
            
        // Utiliza el método del ResourceConfig para determinar si es un archivo grande
        Ok(self.config.resources.is_large_file(metadata.len()))
    }
    
    /// Non-blocking file deletion for large files
    async fn delete_file_non_blocking(&self, abs_path: PathBuf) -> FileRepositoryResult<()> {
        // Check if file is large enough to warrant spawn_blocking
        let is_large = self.is_large_file(&abs_path).await?;
        
        if is_large {
            tracing::info!("Using non-blocking deletion for large file: {}", abs_path.display());
            
            // Use spawn_blocking for large files to prevent blocking the runtime
            task::spawn_blocking(move || {
                // Use standard library's blocking remove_file
                match std::fs::remove_file(&abs_path) {
                    Ok(_) => tracing::info!("Successfully deleted large file: {}", abs_path.display()),
                    Err(e) => tracing::error!("Failed to delete large file: {} - {}", abs_path.display(), e),
                }
            }).await
            .map_err(|e| FileRepositoryError::Other(format!("Join error in spawn_blocking: {}", e)))?;
        } else {
            // For smaller files use tokio's async version
            time::timeout(
                self.config.timeouts.file_timeout(),
                fs::remove_file(&abs_path)
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout deleting file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
        }
        
        Ok(())
    }
}

// Convert IdMappingError to FileRepositoryError
impl From<IdMappingError> for FileRepositoryError {
    fn from(err: IdMappingError) -> Self {
        match err {
            IdMappingError::NotFound(id) => FileRepositoryError::NotFound(id),
            IdMappingError::IoError(e) => FileRepositoryError::IoError(e),
            IdMappingError::Timeout(msg) => FileRepositoryError::Timeout(msg),
            _ => FileRepositoryError::Other(err.to_string()),
        }
    }
}

// Add Timeout variant to FileRepositoryError
impl FileRepositoryError {
    #[allow(dead_code)]
    fn timeout(message: impl Into<String>) -> Self {
        FileRepositoryError::Timeout(message.into())
    }
}

// Los errores ya están definidos por la interfaz FileRepositoryError

// Enable cloning for concurrent operations
impl Clone for FileFsRepository {
    fn clone(&self) -> Self {
        Self {
            root_path: self.root_path.clone(),
            storage_mediator: self.storage_mediator.clone(),
            id_mapping_service: self.id_mapping_service.clone(),
            path_service: self.path_service.clone(),
            metadata_cache: self.metadata_cache.clone(),
            config: self.config.clone(),
            parallel_processor: self.parallel_processor.clone(),
        }
    }
}

#[async_trait]
impl FileStoragePort for FileFsRepository {
    async fn save_file(
        &self,
        name: String,
        folder_id: Option<String>,
        content_type: String,
        content: Vec<u8>,
    ) -> Result<File, DomainError> {
        self.save_file_from_bytes(name, folder_id, content_type, content)
            .await
            .with_context(|| "Failed to save file")
    }
    
    async fn get_file(&self, id: &str) -> Result<File, DomainError> {
        self.get_file_by_id(id)
            .await
            .with_context(|| format!("Failed to get file with ID: {}", id))
    }
    
    async fn list_files(&self, folder_id: Option<&str>) -> Result<Vec<File>, DomainError> {
        FileRepository::list_files(self, folder_id)
            .await
            .with_context(|| format!("Failed to list files in folder: {:?}", folder_id))
    }
    
    async fn delete_file(&self, id: &str) -> Result<(), DomainError> {
        FileRepository::delete_file(self, id)
            .await
            .with_context(|| format!("Failed to delete file with ID: {}", id))
    }
    
    async fn get_file_content(&self, id: &str) -> Result<Vec<u8>, DomainError> {
        FileRepository::get_file_content(self, id)
            .await
            .with_context(|| format!("Failed to get content for file with ID: {}", id))
    }
    
    async fn get_file_stream(&self, id: &str) -> Result<Box<dyn Stream<Item = Result<Bytes, std::io::Error>> + Send>, DomainError> {
        FileRepository::get_file_stream(self, id)
            .await
            .with_context(|| format!("Failed to get stream for file with ID: {}", id))
    }
    
    async fn move_file(&self, file_id: &str, target_folder_id: Option<String>) -> Result<File, DomainError> {
        // Clone target_folder_id before passing to avoid ownership issues
        let cloned_target = target_folder_id.clone();
        let result = FileRepository::move_file(self, file_id, target_folder_id)
            .await;
            
        result.with_context(|| format!("Failed to move file with ID: {} to folder: {:?}", file_id, cloned_target))
    }
    
    async fn get_file_path(&self, id: &str) -> Result<StoragePath, DomainError> {
        FileRepository::get_file_path(self, id)
            .await
            .with_context(|| format!("Failed to get path for file with ID: {}", id))
    }
}

#[async_trait]
impl FileRepository for FileFsRepository {
    async fn save_file_from_bytes(
        &self,
        name: String,
        folder_id: Option<String>,
        content_type: String,
        content: Vec<u8>,
    ) -> FileRepositoryResult<File>
    {
        // Get the folder path from the mediator
        let folder_path = match &folder_id {
            Some(id) => {
                match self.storage_mediator.get_folder_path(id).await {
                    Ok(path) => {
                        tracing::info!("Using folder path: {:?} for folder_id: {:?}", path, id);
                        // Convert to StoragePath
                        let path_str = path.to_string_lossy().to_string();
                        StoragePath::from_string(&path_str)
                    },
                    Err(e) => {
                        tracing::error!("Error getting folder: {}", e);
                        // Root path
                        StoragePath::root()
                    },
                }
            },
            None => StoragePath::root(),
        };
        
        // Create the storage path for the file
        let mut file_storage_path = folder_path.join(&name);
        tracing::info!("Created file path: {:?}", file_storage_path.to_string());
        
        // Check if file already exists and generate a unique name if needed
        let mut exists = self.file_exists_at_storage_path(&file_storage_path).await?;
        tracing::info!("File exists check: {} for path: {:?}", exists, file_storage_path.to_string());
        
        // If file exists, generate a unique name by adding a suffix
        let mut original_name = name.clone();
        let mut counter = 1;
        
        while exists {
            // Extract filename and extension
            let file_stem;
            let extension;
            
            if let Some(dot_pos) = original_name.rfind('.') {
                file_stem = original_name[..dot_pos].to_string();
                extension = original_name[dot_pos..].to_string();
            } else {
                file_stem = original_name.clone();
                extension = "".to_string();
            }
            
            // Create new name with counter
            let new_name = format!("{}_{}{}", file_stem, counter, extension);
            
            // Update the storage path with the new name
            let new_file_storage_path = folder_path.join(&new_name);
            
            // Check if the new path exists
            exists = self.file_exists_at_storage_path(&new_file_storage_path).await?;
            
            if !exists {
                // Update variables for the new path
                tracing::info!("Generated unique name for duplicate file: {} -> {}", original_name, new_name);
                original_name = new_name.clone();
                file_storage_path = new_file_storage_path;
            } else {
                // Try next counter
                counter += 1;
            }
        }
        
        // Create parent directories if they don't exist
        let abs_path = self.resolve_storage_path(&file_storage_path);
        self.ensure_parent_directory(&abs_path).await?;
        
        // Calculate file size
        let content_size = content.len() as u64;
        
        // Verificar si el archivo es muy grande para el procesamiento paralelo de escritura
        if self.config.resources.needs_parallel_processing(content_size, &self.config.concurrency) {
            // Para archivos muy grandes, usar procesador paralelo
            tracing::info!("Using parallel file processor for large file write: {} ({} bytes)", 
                         abs_path.display(), content_size);
            
            // Usar el procesador pre-configurado si está disponible o crear uno nuevo
            let result = if let Some(processor) = &self.parallel_processor {
                tracing::debug!("Using pre-configured parallel processor with buffer pool");
                processor.write_file_parallel(&abs_path, &content).await
            } else {
                tracing::debug!("Creating on-demand parallel processor");
                // Importar y crear el procesador paralelo
                use crate::infrastructure::repositories::parallel_file_processor::ParallelFileProcessor;
                let processor = ParallelFileProcessor::new(self.config.clone());
                
                // Escribir archivo en paralelo
                processor.write_file_parallel(&abs_path, &content).await
            };
            
            // Manejar resultado
            result?;
            
            tracing::info!("Successfully wrote {}MB file using parallel chunks", content_size / (1024 * 1024));
        } else if content_size > self.config.resources.large_file_threshold_mb * 1024 * 1024 {
            // Para archivos grandes pero no tanto como para paralelizar, usar chunking
            let file_creation_result = time::timeout(
                self.config.timeouts.file_timeout(), 
                TokioFile::create(&abs_path)
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout creating file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
            
            let mut file = file_creation_result;
            
            // Define el tamaño del chunk usando la configuración
            let chunk_size = self.config.resources.chunk_size_bytes;
            
            tracing::info!("Using chunked writing with size {} bytes for file: {} ({} bytes)", 
                         chunk_size, abs_path.display(), content_size);
            
            // Divide el contenido en chunks y escribe cada uno con timeout
            for (i, chunk) in content.chunks(chunk_size).enumerate() {
                let _write_result = time::timeout(
                    self.config.timeouts.file_timeout(),
                    file.write_all(chunk)
                ).await
                .map_err(|_| FileRepositoryError::Timeout(
                    format!("Timeout writing chunk {} to file: {}", i, abs_path.display())
                ))?
                .map_err(FileRepositoryError::IoError)?;
                
                tracing::debug!("Written chunk {} ({} bytes) to file {}", i, chunk.len(), abs_path.display());
            }
            
            // Ensure file is properly flushed and closed
            let _flush_result = time::timeout(
                self.config.timeouts.file_timeout(),
                file.flush()
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout flushing file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
        } else {
            // Para archivos pequeños, escritura simple
            let file_creation_result = time::timeout(
                self.config.timeouts.file_timeout(), 
                TokioFile::create(&abs_path)
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout creating file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
            
            let mut file = file_creation_result;
            
            // Para archivos pequeños, escribe todo el contenido de una vez
            let _write_result = time::timeout(
                self.config.timeouts.file_timeout(),
                file.write_all(&content)
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout writing to file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
            
            // Ensure file is properly flushed and closed
            let _flush_result = time::timeout(
                self.config.timeouts.file_timeout(),
                file.flush()
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout flushing file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
        }
        
        // Get file metadata
        let (size, created_at, modified_at) = self.get_file_metadata(&abs_path).await?;
            
        // Determine the MIME type
        let mime_type = if content_type.is_empty() {
            from_path(&abs_path)
                .first_or_octet_stream()
                .to_string()
        } else {
            content_type
        };
        
        // Create and return the file entity with a persistent ID
        let id = self.id_mapping_service.get_or_create_id(&file_storage_path).await?;
        
        // Keep a string representation of the path for logging
        let path_string = file_storage_path.to_string();
        
        let file = self.create_file_entity(
            id,
            original_name, // Use the potentially modified name with counter suffix
            file_storage_path,
            size,
            mime_type,
            folder_id,
            Some(created_at),
            Some(modified_at),
        ).await?;
        
        // Ensure ID mapping is persisted
        self.id_mapping_service.save_changes().await?;
        
        // Invalidate any directory cache entries for the parent folders
        // to ensure directory listings show the new file
        if let Some(parent_dir) = abs_path.parent() {
            self.metadata_cache.invalidate_directory(parent_dir).await;
        }
        
        tracing::info!("Saved file: {} with ID: {}", path_string, file.id());
        Ok(file)
    }
    
    async fn save_file_with_id(
        &self,
        id: String,
        name: String,
        folder_id: Option<String>,
        content_type: String,
        content: Vec<u8>,
    ) -> FileRepositoryResult<File>
    {
        // Get the folder path from the mediator
        let folder_path = match &folder_id {
            Some(fid) => {
                match self.storage_mediator.get_folder_path(fid).await {
                    Ok(path) => {
                        tracing::info!("Using folder path: {:?} for folder_id: {:?}", path, fid);
                        // Convert to StoragePath
                        let path_str = path.to_string_lossy().to_string();
                        StoragePath::from_string(&path_str)
                    },
                    Err(e) => {
                        tracing::error!("Error getting folder: {}", e);
                        // Root path
                        StoragePath::root()
                    },
                }
            },
            None => StoragePath::root(),
        };
        
        // Create the storage path for the file
        let file_storage_path = folder_path.join(&name);
        tracing::info!("Created file path with ID: {:?} for file: {}", file_storage_path.to_string(), id);
        
        // Check if file already exists (and handle overwrites if needed)
        let exists = self.file_exists_at_storage_path(&file_storage_path).await?;
        tracing::info!("File exists check: {} for path: {:?}", exists, file_storage_path.to_string());
        
        // For save_file_with_id, force overwrite if needed
        let abs_path = self.resolve_storage_path(&file_storage_path);
        if exists {
            tracing::warn!("File already exists at path: {:?} - will overwrite", file_storage_path.to_string());
            // Delete the existing file with non-blocking approach
            self.delete_file_non_blocking(abs_path.clone()).await?;
        }
        
        // Create parent directories if they don't exist
        self.ensure_parent_directory(&abs_path).await?;
        
        // Write the file with timeout
        let file_creation_result = time::timeout(
            self.config.timeouts.file_timeout(), 
            TokioFile::create(&abs_path)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout creating file: {}", abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
        
        let mut file = file_creation_result;
        
        let _write_result = time::timeout(
            self.config.timeouts.file_timeout(),
            file.write_all(&content)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout writing to file: {}", abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
        
        // Ensure file is properly flushed and closed
        let _flush_result = time::timeout(
            self.config.timeouts.file_timeout(),
            file.flush()
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout flushing file: {}", abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
        
        // Get file metadata
        let (size, created_at, modified_at) = self.get_file_metadata(&abs_path).await?;
            
        // Determine the MIME type
        let mime_type = if content_type.is_empty() {
            from_path(&abs_path)
                .first_or_octet_stream()
                .to_string()
        } else {
            content_type
        };
        
        // Update the ID mapping for this path
        self.id_mapping_service.update_path(&id, &file_storage_path).await
            .map_err(|e| {
                // Domain errors should be mapped to appropriate FileRepositoryError
                if e.kind == crate::common::errors::ErrorKind::NotFound {
                    // If no previous mapping exists, treat this as a new mapping
                    tracing::info!("No existing ID mapping found for {}, creating new mapping", id);
                    FileRepositoryError::Other("ID not found in mapping, but continuing with new mapping".to_string())
                } else {
                    FileRepositoryError::from(e)
                }
            })?;
        
        // Keep a string representation of the path for logging
        let path_string = file_storage_path.to_string();
        
        // Create the file entity with the provided ID
        let file = self.create_file_entity(
            id.clone(),
            name,
            file_storage_path,
            size,
            mime_type,
            folder_id,
            Some(created_at),
            Some(modified_at),
        ).await?;
        
        // Save changes to mapping service
        self.id_mapping_service.save_changes().await?;
        
        tracing::info!("Saved file with specific ID: {} at path: {}", id, path_string);
        Ok(file)
    }
    
    async fn get_file_by_id(&self, id: &str) -> FileRepositoryResult<File> {
        // Find path by ID using the mapping service
        let storage_path = self.id_mapping_service.get_path_by_id(id).await
            .map_err(FileRepositoryError::from)?;
        
        // Check if file exists physically
        let abs_path = self.resolve_storage_path(&storage_path);
        if !abs_path.exists() || !abs_path.is_file() {
            tracing::error!("File not found at path: {}", abs_path.display());
            return Err(FileRepositoryError::NotFound(format!("File {} not found at {}", id, storage_path.to_string())));
        }
        
        // Get file metadata
        let (size, created_at, modified_at) = self.get_file_metadata(&abs_path).await?;
        
        // Get file name from the storage path
        let name = match storage_path.file_name() {
            Some(name) => name,
            None => {
                tracing::error!("Invalid file path: {}", storage_path.to_string());
                return Err(FileRepositoryError::InvalidPath(storage_path.to_string()));
            }
        };
        
        // Determine parent folder ID - we need to handle this based on storage path
        // This is a simplification - in a real system we might need to look up the folder ID
        let parent = storage_path.parent();
        let folder_id: Option<String> = if parent.is_none() || parent.as_ref().unwrap().is_empty() {
            None // Root folder
        } else {
            // For simplicity, we'll leave this as None for now
            // In a real implementation, you would look up the parent folder ID
            None
        };
        
        // Determine MIME type
        let mime_type = from_path(&abs_path)
            .first_or_octet_stream()
            .to_string();
        
        // Create file entity
        let file = self.create_file_entity(
            id.to_string(),
            name,
            storage_path,
            size,
            mime_type,
            folder_id,
            Some(created_at),
            Some(modified_at),
        ).await?;
        
        Ok(file)
    }
    
    async fn list_files(&self, folder_id: Option<&str>) -> FileRepositoryResult<Vec<File>> {
        tracing::info!("Listing files in folder_id: {:?}", folder_id);
        
        // Get the folder storage path
        let folder_storage_path = match folder_id {
            Some(id) => {
                match self.storage_mediator.get_folder_path(id).await {
                    Ok(path) => {
                        tracing::info!("Found folder with path: {:?}", path);
                        let path_str = path.to_string_lossy().to_string();
                        StoragePath::from_string(&path_str)
                    },
                    Err(e) => {
                        tracing::error!("Error getting folder by ID: {}: {}", id, e);
                        return Ok(Vec::new());
                    },
                }
            },
            None => StoragePath::root(),
        };
        
        // Get the absolute folder path
        let abs_folder_path = self.resolve_storage_path(&folder_storage_path);
        tracing::info!("Absolute folder path: {:?}", abs_folder_path);
        
        // Check if the directory exists
        if !abs_folder_path.exists() || !abs_folder_path.is_dir() {
            tracing::error!("Directory does not exist or is not a directory: {:?}", abs_folder_path);
            return Ok(Vec::new());
        }
        
        // Read directory entries
        let mut files_result = Vec::new();
        
        // Read the directory entries
        match fs::read_dir(&abs_folder_path).await {
            Ok(mut entries) => {
                while let Some(entry) = entries.next_entry().await.unwrap_or(None) {
                    let path = entry.path();
                    
                    // Skip if not a file
                    if !path.is_file() {
                        continue;
                    }
                    
                    // Skip special files
                    let file_name_lossy = entry.file_name().to_string_lossy().to_string();
                    if file_name_lossy.starts_with('.') || file_name_lossy == "folder_ids.json" || file_name_lossy == "file_ids.json" {
                        continue;
                    }
                    
                    // Get file metadata
                    let metadata = match fs::metadata(&path).await {
                        Ok(m) => m,
                        Err(e) => {
                            tracing::error!("Error getting metadata for {:?}: {}", path, e);
                            continue;
                        }
                    };
                    
                    let file_name = file_name_lossy;
                    let file_storage_path = folder_storage_path.join(&file_name);
                    
                    // Get or create an ID for this file
                    let id = match self.id_mapping_service.get_or_create_id(&file_storage_path).await {
                        Ok(id) => id,
                        Err(e) => {
                            tracing::error!("Error getting ID for file: {}", e);
                            continue;
                        }
                    };
                    
                    // Extract metadata
                    let size = metadata.len();
                    
                    // Get creation timestamp
                    let created_at = metadata.created()
                        .map(|time| time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs())
                        .unwrap_or_else(|_| 0);
                        
                    // Get modification timestamp
                    let modified_at = metadata.modified()
                        .map(|time| time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs())
                        .unwrap_or_else(|_| 0);
                    
                    // Determine MIME type
                    let mime_type = from_path(&path)
                        .first_or_octet_stream()
                        .to_string();
                    
                    // Create file entity
                    match File::with_timestamps(
                        id,
                        file_name.clone(),
                        file_storage_path,
                        size,
                        mime_type,
                        folder_id.map(String::from),
                        created_at,
                        modified_at,
                    ) {
                        Ok(file) => {
                            tracing::info!("Added file to result list: {}", file.name());
                            files_result.push(file);
                        },
                        Err(e) => {
                            tracing::error!("Error creating file entity for {}: {}", file_name, e);
                            continue;
                        }
                    }
                }
            },
            Err(e) => {
                tracing::error!("Error reading directory {:?}: {}", abs_folder_path, e);
                return Err(FileRepositoryError::IoError(e));
            }
        }
        
        // Persist any new ID mappings that were created
        if !files_result.is_empty() {
            if let Err(e) = self.id_mapping_service.save_changes().await {
                tracing::error!("Error saving ID mappings: {}", e);
            }
        }
        
        tracing::info!("Found {} files in folder {:?}", files_result.len(), folder_id);
        Ok(files_result)
    }
    
    async fn delete_file(&self, id: &str) -> FileRepositoryResult<()> {
        // Get the file first to check if it exists
        let file = self.get_file_by_id(id).await?;
        
        // Delete the physical file with non-blocking approach
        let abs_path = self.resolve_storage_path(file.storage_path());
        tracing::info!("Deleting physical file: {}", abs_path.display());
        
        // Invalidate metadata cache for this file
        self.metadata_cache.invalidate(&abs_path).await;
        
        // Also invalidate any parent directory caches
        if let Some(parent_dir) = abs_path.parent() {
            self.metadata_cache.invalidate_directory(parent_dir).await;
        }
        
        self.delete_file_non_blocking(abs_path).await?;
        
        tracing::info!("Physical file deleted successfully: {}", file.storage_path().to_string());    
        Ok(())
    }
    
    async fn delete_file_entry(&self, id: &str) -> FileRepositoryResult<()> {
        // Get the file to make sure it exists
        let file = self.get_file_by_id(id).await?;
        
        // Delete the physical file
        let abs_path = self.resolve_storage_path(file.storage_path());
        tracing::info!("Deleting physical file and entry for ID: {}", id);
        
        // Try to delete the file with non-blocking approach, but continue even if it fails
        let delete_result = self.delete_file_non_blocking(abs_path).await;
        match &delete_result {
            Ok(_) => tracing::info!("Physical file deleted successfully: {}", file.storage_path().to_string()),
            Err(e) => tracing::warn!("Failed to delete physical file: {} - {}", file.storage_path().to_string(), e),
        };
        
        // Remove the ID mapping
        self.id_mapping_service.remove_id(id).await
            .map_err(FileRepositoryError::from)?;
        
        // Save the updated mappings
        self.id_mapping_service.save_changes().await?;
        
        // Return success even if file deletion failed - we've removed the mapping
        Ok(())
    }
    
    async fn get_file_content(&self, id: &str) -> FileRepositoryResult<Vec<u8>> {
        // Get the file first to check if it exists and get the path
        let file = self.get_file_by_id(id).await?;
        
        // Read the file content with timeout
        let abs_path = self.resolve_storage_path(file.storage_path());
        
        // Obtener el tamaño del archivo antes de leerlo
        let metadata = time::timeout(
            self.config.timeouts.file_timeout(),
            fs::metadata(&abs_path)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout getting metadata: {}", abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
        
        let file_size = metadata.len();
        
        // Check if this can be loaded in memory
        let can_load_in_memory = self.config.resources.can_load_in_memory(file_size);
        
        tracing::info!("File size: {} bytes, can load in memory: {}", file_size, can_load_in_memory);
        
        if !can_load_in_memory {
            return Err(FileRepositoryError::Other(
                format!("File too large to load in memory: {} MB (max: {} MB)", 
                       file_size / (1024 * 1024), 
                       self.config.resources.max_in_memory_file_size_mb)
            ));
        }
        
        // Verificar si el archivo necesita procesamiento paralelo
        if self.config.resources.needs_parallel_processing(file_size, &self.config.concurrency) {
            // Para archivos muy grandes, usar el procesador paralelo
            tracing::info!("Using parallel file processor for large file: {}", abs_path.display());
            
            // Usar el procesador pre-configurado si está disponible o crear uno nuevo
            let content = if let Some(processor) = &self.parallel_processor {
                tracing::debug!("Using pre-configured parallel processor with buffer pool for reading");
                processor.read_file_parallel(&abs_path).await?
            } else {
                tracing::debug!("Creating on-demand parallel processor for reading");
                // Importar el procesador paralelo
                use crate::infrastructure::repositories::parallel_file_processor::ParallelFileProcessor;
                
                // Crear procesador con la configuración actual
                let processor = ParallelFileProcessor::new(self.config.clone());
                
                // Realizar lectura en paralelo
                processor.read_file_parallel(&abs_path).await?
            };
            
            tracing::info!("Successfully read {}MB file in parallel chunks", file_size / (1024 * 1024));
            return Ok(content);
        } else if self.config.resources.is_large_file(file_size) {
            // Para archivos grandes (pero no tanto como para paralelizar), usar spawn_blocking
            tracing::info!("Using spawn_blocking for large file: {}", abs_path.display());
            
            // Use spawn_blocking to prevent blocking the runtime
            let abs_path_clone = abs_path.clone();
            let chunk_size = self.config.resources.chunk_size_bytes;
            
            // Implementación para leer archivos grandes de forma optimizada:
            // 1. Creamos un buffer del tamaño exacto del archivo para evitar realocaciones
            // 2. Leemos el archivo en chunks dentro del spawn_blocking
            let content = task::spawn_blocking(move || -> std::io::Result<Vec<u8>> {
                use std::io::{Read, BufReader};
                use std::fs::File;
                
                // Abre el archivo de forma bloqueante
                let file = File::open(&abs_path_clone)?;
                let mut reader = BufReader::with_capacity(chunk_size, file);
                
                // Crea un buffer del tamaño exacto del archivo
                let mut buffer = Vec::with_capacity(file_size as usize);
                
                // Lee todo el contenido y devuelve el buffer
                reader.read_to_end(&mut buffer)?;
                Ok(buffer)
            }).await
            .map_err(|e| FileRepositoryError::Other(format!("Join error in spawn_blocking: {}", e)))?
            .map_err(FileRepositoryError::IoError)?;
            
            return Ok(content);
        } else {
            // Para archivos pequeños, usar tokio's async version con timeout
            let content = time::timeout(
                self.config.timeouts.file_timeout(),
                fs::read(&abs_path)
            ).await
            .map_err(|_| FileRepositoryError::Timeout(format!("Timeout reading file: {}", abs_path.display())))?
            .map_err(FileRepositoryError::IoError)?;
            
            return Ok(content);
        }
    }
    
    async fn get_file_stream(&self, id: &str) -> FileRepositoryResult<Box<dyn Stream<Item = Result<Bytes, std::io::Error>> + Send>> {
        // Get the file first to check if it exists and get the path
        let file = self.get_file_by_id(id).await?;
        
        // Open the file for reading with timeout
        let abs_path = self.resolve_storage_path(file.storage_path());
        
        // Obtenemos el tamaño del archivo para definir el tamaño óptimo de los chunks
        let metadata = time::timeout(
            self.config.timeouts.file_timeout(),
            fs::metadata(&abs_path)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout getting metadata for stream: {}", abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
        
        let file_size = metadata.len();
        let is_large = self.config.resources.is_large_file(file_size);
        
        // Abrimos el archivo con timeout
        let file = time::timeout(
            self.config.timeouts.file_timeout(),
            TokioFile::open(&abs_path)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout opening file stream for: {}", file.storage_path().to_string())))?
        .map_err(FileRepositoryError::IoError)?;
        
        // Definir tamaño de chunk óptimo según el tamaño del archivo
        let chunk_size = if is_large {
            // Para archivos grandes usamos el tamaño de chunk configurado
            self.config.resources.chunk_size_bytes
        } else {
            // Para archivos pequeños usamos un tamaño menor para maximizar eficiencia
            4096 // 4KB standard para archivos pequeños
        };
        
        tracing::info!("Streaming file {} (size: {} bytes) with chunk size: {}", 
                     abs_path.display(), file_size, chunk_size);
        
        // Creamos un codec con el tamaño de chunk optimizado
        let codec = BytesCodec::new();
        
        // Create a stream from the file, map BytesMut to Bytes, and box it
        let stream = FramedRead::with_capacity(file, codec, chunk_size)
            .map(|result| {
                result.map(|bytes_mut| {
                    // Convert BytesMut to Bytes (freeze)
                    bytes_mut.freeze()
                })
            });
            
        Ok(Box::new(stream))
    }
    
    async fn move_file(&self, id: &str, target_folder_id: Option<String>) -> FileRepositoryResult<File> {
        // Get the original file
        let original_file = self.get_file_by_id(id).await?;
        
        // If the target folder is the same as the current one, no need to move
        if original_file.folder_id() == target_folder_id.as_deref() {
            tracing::info!("File is already in the target folder, no need to move");
            return Ok(original_file);
        }
        
        // Get the target folder path
        let target_folder_path = match &target_folder_id {
            Some(folder_id) => {
                match self.storage_mediator.get_folder_path(folder_id).await {
                    Ok(path) => {
                        let path_str = path.to_string_lossy().to_string();
                        StoragePath::from_string(&path_str)
                    },
                    Err(e) => {
                        return Err(FileRepositoryError::Other(
                            format!("Could not get target folder: {}", e)
                        ));
                    }
                }
            },
            None => StoragePath::root()
        };
        
        // Create the new file path
        let new_storage_path = target_folder_path.join(original_file.name());
        
        // Check if a file already exists at the destination
        if self.file_exists_at_storage_path(&new_storage_path).await? {
            return Err(FileRepositoryError::AlreadyExists(
                format!("File already exists at destination: {}", new_storage_path.to_string())
            ));
        }
        
        // Get absolute paths
        let old_abs_path = self.resolve_storage_path(original_file.storage_path());
        let new_abs_path = self.resolve_storage_path(&new_storage_path);
        
        // Ensure the target directory exists
        self.ensure_parent_directory(&new_abs_path).await?;
        
        // Move the file physically (efficient rename operation) with timeout
        time::timeout(
            self.config.timeouts.file_timeout(),
            fs::rename(&old_abs_path, &new_abs_path)
        ).await
        .map_err(|_| FileRepositoryError::Timeout(format!("Timeout moving file from {} to {}", 
                                                        old_abs_path.display(), new_abs_path.display())))?
        .map_err(FileRepositoryError::IoError)?;
            
        tracing::info!("File moved successfully from {:?} to {:?}", old_abs_path, new_abs_path);
        
        // Update the ID mapping
        self.id_mapping_service.update_path(id, &new_storage_path).await
            .map_err(FileRepositoryError::from)?;
        
        // Save the updated mappings
        self.id_mapping_service.save_changes().await?;
        
        // Create and return the updated file entity
        // Create an immutable new version of the file with the updated folder
        let moved_file = original_file.with_folder(target_folder_id, Some(target_folder_path))
            .map_err(|e| FileRepositoryError::Other(e.to_string()))?;
        
        Ok(moved_file)
    }
    
    async fn get_file_path(&self, id: &str) -> FileRepositoryResult<StoragePath> {
        // Use the ID mapping service to get the storage path
        let storage_path = self.id_mapping_service.get_path_by_id(id).await
            .map_err(FileRepositoryError::from)?;
        
        Ok(storage_path)
    }
}